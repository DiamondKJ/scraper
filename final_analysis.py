# final_analysis.py (Version 2 - With Confidence Filtering)

import pandas as pd

# Set pandas to display wider columns so you can read the comment text
pd.set_option('display.max_colwidth', 200)

print("--- Starting Final Analysis (with Confidence Score Filtering) ---")

CONFIDENCE_THRESHOLD = 0.60  # <--- CRUCIAL: Set your confidence threshold here

# --- Load Your Classified Data ---
try:
    # Use the filename generated by the analyze_data.py script
    classified_comments_df = pd.read_csv('classified_relevant_comments_option_b.csv')
    print(f"\nSuccessfully loaded {len(classified_comments_df)} total classified comments.")
except FileNotFoundError:
    print("Error: 'classified_relevant_comments_option_b.csv' not found.")
    print("Please make sure you have run analyze_data.py successfully first.")
    exit()

# --- 1. Filter for Your Specific Research Question ---
# First, select all rows that the model *attempted* to classify as your target.
cognitive_fatigue_candidates = classified_comments_df[
    classified_comments_df['fatigue_classification'] == 'cognitive fatigue related to peptides'
].copy()

print(f"\nFound {len(cognitive_fatigue_candidates)} candidate comments classified as 'cognitive fatigue related to peptides' (before confidence filtering).")


# --- 2. Apply the Confidence Score Filter ---
# This is the most important step to ensure data quality.
high_confidence_comments = cognitive_fatigue_candidates[
    cognitive_fatigue_candidates['classification_confidence'] >= CONFIDENCE_THRESHOLD
].copy()

print(f"\nFound {len(high_confidence_comments)} high-confidence comments after applying a threshold of {CONFIDENCE_THRESHOLD}.")


# --- 3. Analyze the High-Confidence Results ---
if not high_confidence_comments.empty:
    print("\n--- Sample of HIGHLY RELEVANT Comments (Confidence >= " + str(CONFIDENCE_THRESHOLD) + ") ---")
    # Display the most relevant columns for a qualitative check
    print(high_confidence_comments[[
        'comment_text_cleaned',
        'classification_confidence',
        'subreddit',
        'post_title'
    ]].head(20).to_string()) # Show more examples

    # Sort by confidence to see the "strongest" examples
    strongest_examples = high_confidence_comments.sort_values(by='classification_confidence', ascending=False)
    print("\n--- Top 10 Strongest Examples (by confidence score) ---")
    print(strongest_examples[[
        'comment_text_cleaned',
        'classification_confidence'
    ]].head(10).to_string())

    # Save this final, high-quality dataset for your dissertation
    final_dataset_filename = 'FINAL_HIGH_CONFIDENCE_cognitive_fatigue_comments.csv'
    strongest_examples.to_csv(final_dataset_filename, index=False)
    print(f"\nSaved the final, high-quality dataset to '{final_dataset_filename}'")

else:
    print("\nNo high-confidence comments were found for 'cognitive fatigue related to peptides'.")
    print("This suggests that while the topic is discussed, direct statements about this specific fatigue are rare.")
    print("Consider lowering the threshold (e.g., to 0.6) or re-evaluating keyword lists if the count is zero.")

print("\n--- Final Analysis Complete ---")


print("\n--- Creating JSON file for Netlify deployment ---")
if not high_confidence_comments.empty:
    json_output_filename = 'netlify/functions/comments.json'
    high_confidence_comments.to_json(json_output_filename, orient='records', indent=2)
    print(f"Successfully created '{json_output_filename}' with {len(high_confidence_comments)} records.")
else:
    print("Skipping JSON creation because no high-confidence comments were found.")